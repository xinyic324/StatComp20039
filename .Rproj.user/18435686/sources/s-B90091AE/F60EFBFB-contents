---
title: "Homework-2020.11.10"
author: 'By 20039'
date: "2020/11/10"
output: html_document
---

## 练习1

Exercise 8.3 (page 243, Statistical Computating with R).
The Count 5 test for equal variances in Section 6.4 is based on the maximum
number of extreme points. Example 6.15 shows that the Count 5 criterion
is not applicable for unequal sample sizes. Implement a permutation test for
equal variance based on the maximum number of extreme points that applies
when sample sizes are not necessarily equal.

## answer







r包
stats rgamma runif
graphics
MASS
bootstrap
boot
DAAG
RANN
energy
Ball
kedd
























```{r}
jk=function(X,Y,d){
  m1=nrow(X)
  m2=nrow(Y)
  m3=ncol(X)
  m4=ncol(Y)
  XY=rbind(X,Y)
  u=apply(XY,2,mean)
  u1=apply(X,2,mean)
  u2=apply(Y,2,mean)
  sb=m1*((u1-u)%*%t(u1-u))+m2*((u2-u)%*%t(u2-u))
  sw1=matrix(0,nrow = m3,ncol = m3)
  sw2=matrix(0,nrow = m4,ncol = m4)
  for (i in 1:m1) {
    sw1=as.matrix((u1-X[i,]))%*%t(as.matrix((u1-X[i,])))+sw1
  }
  for (j in 1:m2) {
    sw2=as.matrix((u2-Y[j,]))%*%t(as.matrix((u2-Y[j,])))+sw2
  }
  sw=sw1+sw2
  w=solve(sw)%*%sb
  wl=eigen(w)
  M=wl$vectors
  w0=M[,c(1:d)]
  X1=X%*%w0
  Y1=Y%*%w0
  return(list(x1=X1,y1=Y1,vectors=M))
} 
library(StatComp20039)
X=matrix(c(2.95,6.63,2.53,7.79,3.57,5.65,3.16,5.47),nrow = 4,ncol = 2,byrow = TRUE)
Y=matrix(c(2.58,4.46,2.16,6.22,3.27,3.52),nrow = 3,ncol = 2,byrow = TRUE)
m=jk(X=X,Y=Y,d=1)$vectors
m
```
From the results of the permutation test,we can know that the value of p is large enough.
So we can't reject the null hypothesis.The test results are quite appropriate.


## 练习2

Design experiments for evaluating the performance of the NN,
energy, and ball methods in various situations.
1. Unequal variances and equal expectations
2. Unequal variances and unequal expectations.
3. Non-normal distributions: t distribution with 1 df (heavy-tailed
distribution), bimodel distribution (mixture of two normal
distributions)
4. Unbalanced samples (say, 1 case versus 10 controls)
5.Note: The parameters should be chosen such that the powers
are distinguishable (say, range from 0.3 to 0.8)

## answer

1.Unequal variances and equal expectations.$X\sim N(0.3,1.5^2)$,$Y\sim N(0.3,1)$
```{r}
library(RANN)
library(boot)
library(energy)
library(Ball)
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}
set.seed(12345)
m<-1e3
k<-3
p<-2
mu<-0.3
n1<-50
n2<-50
R<-999
n<-n1+n2
N<-c(n1,n2)
eqdist.nn<-function(n,sizes,k){
  boot.obj<-boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rnorm(n1*p,mean=mu,sd=1.5),ncol=p);
y <- cbind(rnorm(n2,mean=mu),rnorm(n2,mean=mu));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow1 <- colMeans(p.values<alpha)
pow1
```


2. Unequal variances and unequal expectations.$X\sim N(0.3,1.5^2)$,$Y\sim N(0.5,1)$.
```{r}
library(RANN)
library(boot)
library(energy)
library(Ball)
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}
set.seed(12345)
m<-1e3
k<-3
p<-2
mu<-0.3
mu1<-0.5
n1<-50
n2<-50
R<-999
n<-n1+n2
N<-c(n1,n2)
eqdist.nn<-function(n,sizes,k){
  boot.obj<-boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rnorm(n1*p,mean=mu1,sd=1.5),ncol=p);
y <- cbind(rnorm(n2,mean=mu,sd=1),rnorm(n2,mean=mu,sd=1));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow2 <- colMeans(p.values<alpha)
pow2
```


3.Non-normal distributions: t distribution with 1 df (heavy-tailed
distribution), bimodel distribution (mixture of two normal
distributions)
(a)$X\sim t(1)$,the cdf of $Y$ is $F(y)=0.8*\phi(y;0,1)+0.2*\phi(y;0,100)$
```{r}
library(RANN)
library(boot)
library(energy)
library(Ball)
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}
set.seed(12345)
m<-1e3
k<-3
p<-2
p1<-0.8
n1<-50
n2<-50
R<-999
n<-n1+n2
N<-c(n1,n2)
eqdist.nn<-function(n,sizes,k){
  boot.obj<-boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rt(n1*p,df=1),ncol=p);
sigma<- sample(c(1, 10), size = n2,
replace = TRUE, prob = c(p1, 1-p1))
y <- cbind(rnorm(n2,mean=0,sd=sigma),rnorm(n2,mean=0,sd=sigma));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow3 <- colMeans(p.values<alpha)
pow3
```

(b)Non-normal distributions: t distribution with 1 df (heavy-tailed
distribution).$X\sim t(1)$,$Y\sim t(2)$
```{r}
library(RANN)
library(boot)
library(energy)
library(Ball)
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}
set.seed(12345)
m<-1e3
k<-3
p<-2
p1<-0.8
n1<-50
n2<-50
R<-999
n<-n1+n2
N<-c(n1,n2)
eqdist.nn<-function(n,sizes,k){
  boot.obj<-boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rt(n1*p,df=1),ncol=p);
y <- cbind(rt(n2,df=2),rt(n2,df=2));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow6 <- colMeans(p.values<alpha)
pow6
```


(C)Non-normal distributions: bimodel distribution (mixture of two normal
distributions)
$F(X)=0.9\phi(0;1)+0.1\phi(0;4) $,$F(Y)=0.8\phi(0;1)+0.2\phi(0;9) $
```{r}
library(RANN)
library(boot)
library(energy)
library(Ball)
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}
set.seed(12345)
m<-1e3
k<-3
p<-2
p1<-0.8
p2<-0.9
n1<-50
n2<-50
R<-999
n<-n1+n2
N<-c(n1,n2)
eqdist.nn<-function(n,sizes,k){
  boot.obj<-boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
sigma<- sample(c(1, 3), size = n2,
replace = TRUE, prob = c(p1, 1-p1))
sigma1<- sample(c(1, 2), size = n2,
replace = TRUE, prob = c(p2, 1-p2))
x <-cbind(rnorm(n1,mean=0,sd=sigma1),rnorm(n1,mean=0,sd=sigma1));
y <- cbind(rnorm(n2,mean=0,sd=sigma),rnorm(n2,mean=0,sd=sigma));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow3 <- colMeans(p.values<alpha)
pow3
```



4. Unbalanced samples (say, 1 case versus 10 controls).$X\sim N(0.3,1)\quad(n1=10)$,$Y\sim N(0.3,1) \quad(n2=100)$
```{r}
library(RANN)
library(boot)
library(energy)
library(Ball)
Tn <- function(z, ix, sizes,k) {
n1 <- sizes[1]; n2 <- sizes[2]; n <- n1 + n2
if(is.vector(z)) z <- data.frame(z,0);
z <- z[ix, ];
NN <- nn2(data=z, k=k+1) # what's the first column?
block1 <- NN$nn.idx[1:n1,-1]
block2 <- NN$nn.idx[(n1+1):n,-1]
i1 <- sum(block1 < n1 + .5); i2 <- sum(block2 > n1+.5)
(i1 + i2) / (k * n)
}
set.seed(12345)
m<-1e3
k<-3
p<-2
mu<-0.3
n1<-10
n2<-100
R<-999
n<-n1+n2
N<-c(n1,n2)
eqdist.nn<-function(n,sizes,k){
  boot.obj<-boot(data=z,statistic=Tn,R=R,
sim = "permutation", sizes = sizes,k=k)
  ts <- c(boot.obj$t0,boot.obj$t)
p.value <- mean(ts>=ts[1])
list(statistic=ts[1],p.value=p.value)
}
p.values <- matrix(NA,m,3)
for(i in 1:m){
x <- matrix(rnorm(n1*p,mean=mu,sd=1),ncol=p);
y <- cbind(rnorm(n2,mean=mu,sd=1),rnorm(n2,mean=mu,sd=1));
z <- rbind(x,y)
p.values[i,1] <- eqdist.nn(z,N,k)$p.value
p.values[i,2] <- eqdist.etest(z,sizes=N,R=R)$p.value
p.values[i,3] <- bd.test(x=x,y=y,num.permutations=999,seed=i*12345)$p.value
}
alpha <- 0.1;
pow4 <- colMeans(p.values<alpha)
pow4
```
As We can see from the results,Ball could be more powerful for non-location family distribution
(e.g., the variances are different)
Energy test and Ball test are generally more powerful than
nearest NN test, but the former two cannot uniformly each
other.